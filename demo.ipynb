{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class DotProductAttention(nn.Module):  \n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"Scaled dot product attention.\"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        self.attention_weights = torch.matmul(\n",
    "            queries, \n",
    "            keys.T\n",
    "        ) / math.sqrt(d)\n",
    "        return torch.matmul(\n",
    "            self.dropout(self.attention_weights), \n",
    "            values\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = DotProductAttention(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.randn(256, 64)\n",
    "item = torch.randn(256, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(user, item, item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, embed_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout, bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.LazyLinear(embed_dim, bias=bias)\n",
    "        self.W_k = nn.LazyLinear(embed_dim, bias=bias)\n",
    "        self.W_v = nn.LazyLinear(embed_dim, bias=bias)\n",
    "        self.W_o = nn.LazyLinear(embed_dim, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        queries = self.transpose_qkv(self.W_q(queries))\n",
    "        keys = self.transpose_qkv(self.W_k(keys))\n",
    "        values = self.transpose_qkv(self.W_v(values))\n",
    "        output = self.attention(\n",
    "            queries, \n",
    "            keys, \n",
    "            values\n",
    "        )\n",
    "        output_concat = self.transpose_output(output)\n",
    "        return self.W_o(output_concat)\n",
    "    \n",
    "    def transpose_qkv(self, X):\n",
    "        \"\"\"\n",
    "        Transposition for parallel computation of multiple attention heads.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        @param X: torch.Tensor\n",
    "            Shape \n",
    "            (\n",
    "                batch_size, \n",
    "                num_hiddens\n",
    "            ).\n",
    "        @return X: torch.Tensor\n",
    "            Shape \n",
    "            (\n",
    "                batch_size * num_heads, \n",
    "                num_hiddens / num_heads\n",
    "            )\n",
    "        \"\"\"\n",
    "        X = X.reshape(X.shape[0], self.num_heads, -1)\n",
    "        return X.reshape(-1, X.shape[2])\n",
    "\n",
    "    def transpose_output(self, X):\n",
    "        \"\"\"\n",
    "        Reverse the operation of transpose_qkv.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        @param X: torch.Tensor\n",
    "            Shape \n",
    "            (\n",
    "                batch_size * num_heads, \n",
    "                num_hiddens / num_heads\n",
    "            ).\n",
    "        @return X: torch.Tensor\n",
    "            Shape \n",
    "            (\n",
    "                batch_size, \n",
    "                num_hiddens\n",
    "            )\n",
    "        \"\"\"\n",
    "        X = X.reshape(-1, self.num_heads, X.shape[1])\n",
    "        return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/linkdom/miniconda3/miniconda3/envs/LKGCN/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "attention = MultiHeadAttention(64, 8, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(user, item, item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfBlock(nn.Module):  \n",
    "    def __init__(self, embed_dim, num_heads, dropout,\n",
    "                 use_bias=False):\n",
    "        super().__init__()\n",
    "        self.addnorm1 = AddNorm(embed_dim, dropout)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            embed_dim, num_heads,\n",
    "            dropout, use_bias\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 2 * embed_dim, bias=use_bias),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * embed_dim, embed_dim, bias=use_bias),\n",
    "        )\n",
    "        self.addnorm2 = AddNorm(embed_dim, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu_block = SelfBlock(64, 8, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu_block(user).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_block = SelfBlock(64, 8, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii_block(item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossBlock(nn.Module):  \n",
    "    def __init__(self, embed_dim, num_heads, dropout,\n",
    "                 use_bias=False):\n",
    "        super().__init__()\n",
    "        self.addnorm1 = AddNorm(embed_dim, dropout)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            embed_dim, num_heads,\n",
    "            dropout, use_bias\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 2 * embed_dim, bias=use_bias),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * embed_dim, embed_dim, bias=use_bias),\n",
    "        )\n",
    "        self.addnorm2 = AddNorm(embed_dim, dropout)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        Y = self.addnorm1(item, self.attention(item, user, user))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_block = CrossBlock(64, 8, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_block(user, item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn.transformerf import TransforMerF\n",
    "model = TransforMerF(\n",
    "    n_users=1000,\n",
    "    m_items=1000,\n",
    "    embed_dim=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = torch.randint(0,1000,(256,))\n",
    "item = torch.randint(0,1000,(256,))\n",
    "user.shape, item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4154e+01, -1.7320e-01, -1.9497e+00,  1.9831e+00,  1.2043e+01,\n",
       "        -1.0175e+01, -5.1725e+00, -1.0127e+01, -5.5775e+00,  3.1541e+00,\n",
       "         3.8758e-01, -3.3462e+00,  2.0182e+01, -2.5343e+00,  8.0695e+00,\n",
       "        -1.1938e+01, -2.6288e+00, -1.3323e+01,  3.8617e+00, -6.0513e+00,\n",
       "        -7.6396e+00,  1.0637e+01, -1.5773e+00,  4.6440e-01, -7.2481e+00,\n",
       "         5.6005e+00, -6.9028e+00, -7.3112e+00, -4.6141e+00,  9.4800e+00,\n",
       "         1.0274e+01, -2.4179e+01,  7.1802e+00,  2.4965e+00, -5.0181e+00,\n",
       "        -5.3158e+00,  8.6317e+00,  2.8862e-01,  4.7187e+00, -7.6584e+00,\n",
       "         9.7339e+00,  1.1335e+01,  6.3949e+00,  8.3217e+00,  1.1241e+01,\n",
       "        -2.0072e+01,  2.6638e+00, -7.7120e+00,  1.5399e+01,  4.9124e+00,\n",
       "        -7.2256e+00, -1.7304e+00,  4.0716e+00, -8.7875e+00, -6.0653e+00,\n",
       "         9.4789e-01,  3.6162e+00,  1.5173e+01, -5.8039e+00, -5.9595e+00,\n",
       "        -4.9906e+00,  2.3655e+00,  2.1212e+00,  1.0127e+01,  9.7590e+00,\n",
       "         7.9508e+00, -1.9721e+00,  1.6780e+00, -5.8799e+00, -3.4443e+00,\n",
       "         3.0167e+00, -8.5765e+00, -1.5789e+00, -1.5010e+00,  2.1892e+00,\n",
       "         1.1543e+00, -1.1381e+01,  5.0818e+00,  1.0880e+00,  1.3108e+01,\n",
       "         9.2100e+00,  6.3606e+00, -1.6167e+01, -4.5499e+00, -5.4724e+00,\n",
       "        -1.1653e+00, -1.0223e+01, -7.4864e+00, -1.4464e+01, -1.9372e+00,\n",
       "         2.5452e+00, -9.5536e+00, -4.4876e+00,  9.3325e-01, -1.3697e+01,\n",
       "        -3.3158e+00,  7.8528e+00,  7.0595e+00,  3.4881e+00, -8.9099e-01,\n",
       "        -1.0978e+01,  1.3383e+01,  1.4208e+01, -6.5274e+00, -4.8560e+00,\n",
       "        -9.6471e+00,  4.8672e+00,  1.5385e+01,  6.5202e+00,  1.0652e+01,\n",
       "         7.8688e-01,  4.4692e+00, -1.3183e+00,  7.7787e+00,  1.7499e+00,\n",
       "         6.0855e+00,  1.5078e+01,  4.0405e-01, -8.6740e+00, -2.8666e+00,\n",
       "        -7.9736e+00, -1.2671e+01, -6.3643e+00,  5.0943e+00, -1.4222e+01,\n",
       "        -1.0087e+00, -1.5253e+00,  3.2828e-01,  7.2548e+00,  1.2914e+01,\n",
       "        -1.0779e+01, -4.3052e+00, -6.4253e+00,  5.1689e+00,  7.8373e+00,\n",
       "         9.1389e+00, -4.7936e-01,  9.5247e+00,  3.4786e+00, -5.7841e+00,\n",
       "         2.4139e+00,  1.1512e+01,  6.4891e+00, -3.0061e+00,  3.0903e+00,\n",
       "         2.1920e+00,  2.0216e+00, -7.2200e+00, -7.5525e+00, -3.9415e+00,\n",
       "         4.7922e+00,  1.3273e+01, -9.7824e+00, -7.3978e+00,  1.7242e+01,\n",
       "        -2.2029e+00,  1.0887e+01,  6.3030e+00, -7.4949e+00, -2.1721e+00,\n",
       "        -5.5403e+00,  2.7547e-01,  1.5672e+01,  7.4674e+00,  1.0509e+00,\n",
       "         4.9435e+00, -2.4126e-01, -5.1428e+00,  5.6461e+00, -1.3161e+01,\n",
       "         3.9646e-01,  5.6347e+00, -7.0188e+00, -2.1961e+00, -5.0469e+00,\n",
       "         5.5762e+00, -1.8057e+01, -1.9741e+00,  5.6527e-01,  3.0835e+00,\n",
       "         3.2167e+00, -1.1423e+01, -8.5908e+00, -1.8727e+01,  5.7661e+00,\n",
       "         1.4782e-02, -5.5017e+00,  4.0666e+00,  7.4076e+00, -3.7471e+00,\n",
       "         1.0728e+01,  4.1188e+00, -5.8957e+00, -2.1051e+00,  1.4858e+00,\n",
       "         1.2094e+01,  1.0241e+01,  1.1470e+01, -1.9369e+00,  8.8284e+00,\n",
       "        -3.0050e-01,  1.0535e+01,  2.5588e+00, -6.4654e+00, -4.2329e+00,\n",
       "         7.5998e+00, -1.8121e-01,  2.9035e+00,  5.7816e+00,  5.8790e+00,\n",
       "         1.5080e+01,  3.6486e+00,  1.6237e+01,  8.1818e+00,  1.6071e+00,\n",
       "        -2.8771e+00, -8.4870e+00,  1.2341e+01, -8.8290e-01, -6.8958e+00,\n",
       "        -3.3878e+00,  5.0235e+00,  7.5745e-01, -1.9259e-01,  2.6307e+00,\n",
       "         3.5948e+00,  2.6828e+00, -4.8874e+00, -3.9330e+00,  1.0912e+00,\n",
       "        -2.4351e+00,  1.2781e+00,  3.0556e+00, -8.1179e+00,  5.6737e+00,\n",
       "         1.4395e+01,  2.1842e-01,  1.3745e+01, -9.1831e+00,  1.4725e+01,\n",
       "        -6.1284e+00,  1.2245e+00, -5.1159e+00, -5.6143e-01,  1.6147e+00,\n",
       "        -4.9699e+00, -6.9645e-01, -4.0582e+00, -5.7342e+00,  4.3989e+00,\n",
       "        -9.2084e-01, -9.9149e+00, -7.6215e+00,  3.7035e+00, -1.1933e+01,\n",
       "        -3.6700e+00], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LKGCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
